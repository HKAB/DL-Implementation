{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "delayed-child",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "interpreted-stick",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.tensor([2, -3], dtype=torch.float32)\n",
    "b = torch.tensor([2.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "confident-civilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand((1000, 2))\n",
    "y = torch.matmul(X, W) + b\n",
    "y += torch.normal(0.0, 0.01, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "moved-numbers",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_W = torch.rand_like(W, requires_grad=True)\n",
    "train_b = torch.zeros_like(b, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "considerable-ultimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iter(batch_size, X, y):\n",
    "    indies = torch.arange(X.shape[0])\n",
    "    random.shuffle(indies)\n",
    "    \n",
    "    for i in range(0, len(y), batch_size):\n",
    "        X_batch = X[i:i + batch_size]\n",
    "        y_batch = y[i:i + batch_size]\n",
    "        \n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "south-addiction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 2])\n"
     ]
    }
   ],
   "source": [
    "for X, y in data_iter(200, X, y):\n",
    "    print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "informational-festival",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([36.1250])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def loss(y_true, y_pred):\n",
    "    return 1/2*torch.pow((y_pred - y_true), 2)\n",
    "loss(torch.tensor([10.5]), torch.tensor([2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "sublime-render",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linrg(X):\n",
    "    return torch.matmul(X, train_W) + train_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "minimal-intelligence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params, lr, batch_size):\n",
    "    with torch.no_grad():\n",
    "        for param in params:\n",
    "#             print(param.grad)\n",
    "            param -= (lr/batch_size)*param.grad\n",
    "            param.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "pending-orbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "batch_size = 10\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "capable-meeting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0005, train_W: tensor([ 2.0004, -2.9994], requires_grad=True), train_b: tensor([1.9999], requires_grad=True)\n",
      "Loss: 0.0006, train_W: tensor([ 2.0004, -2.9995], requires_grad=True), train_b: tensor([2.0000], requires_grad=True)\n",
      "Loss: 0.0006, train_W: tensor([ 2.0006, -2.9994], requires_grad=True), train_b: tensor([2.0001], requires_grad=True)\n",
      "Loss: 0.0001, train_W: tensor([ 2.0005, -2.9995], requires_grad=True), train_b: tensor([2.0000], requires_grad=True)\n",
      "Loss: 0.0006, train_W: tensor([ 2.0002, -2.9993], requires_grad=True), train_b: tensor([2.0000], requires_grad=True)\n",
      "Loss: 0.0006, train_W: tensor([ 2.0004, -2.9991], requires_grad=True), train_b: tensor([2.0005], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 2.0001, -2.9994], requires_grad=True), train_b: tensor([2.0001], requires_grad=True)\n",
      "Loss: 0.0006, train_W: tensor([ 2.0000, -2.9994], requires_grad=True), train_b: tensor([2.0000], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 1.9999, -2.9995], requires_grad=True), train_b: tensor([1.9998], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 2.0001, -2.9994], requires_grad=True), train_b: tensor([1.9999], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 2.0001, -2.9995], requires_grad=True), train_b: tensor([1.9999], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9999, -2.9996], requires_grad=True), train_b: tensor([1.9996], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9998, -2.9996], requires_grad=True), train_b: tensor([1.9996], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9999, -2.9996], requires_grad=True), train_b: tensor([1.9998], requires_grad=True)\n",
      "Loss: 0.0002, train_W: tensor([ 2.0001, -2.9996], requires_grad=True), train_b: tensor([2.0001], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 2.0001, -2.9995], requires_grad=True), train_b: tensor([2.0001], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 2.0000, -2.9998], requires_grad=True), train_b: tensor([1.9999], requires_grad=True)\n",
      "Loss: 0.0006, train_W: tensor([ 1.9998, -2.9999], requires_grad=True), train_b: tensor([1.9997], requires_grad=True)\n",
      "Loss: 0.0006, train_W: tensor([ 2.0003, -2.9996], requires_grad=True), train_b: tensor([2.0004], requires_grad=True)\n",
      "Loss: 0.0007, train_W: tensor([ 2.0003, -2.9996], requires_grad=True), train_b: tensor([2.0004], requires_grad=True)\n",
      "Loss: 0.0009, train_W: tensor([ 2.0002, -2.9995], requires_grad=True), train_b: tensor([2.0004], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 2.0007, -2.9989], requires_grad=True), train_b: tensor([2.0012], requires_grad=True)\n",
      "Loss: 0.0008, train_W: tensor([ 2.0006, -2.9992], requires_grad=True), train_b: tensor([2.0010], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 2.0004, -2.9996], requires_grad=True), train_b: tensor([2.0004], requires_grad=True)\n",
      "Loss: 0.0006, train_W: tensor([ 2.0002, -2.9998], requires_grad=True), train_b: tensor([1.9998], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 2.0003, -2.9998], requires_grad=True), train_b: tensor([1.9999], requires_grad=True)\n",
      "Loss: 0.0002, train_W: tensor([ 2.0006, -2.9997], requires_grad=True), train_b: tensor([2.0000], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 2.0005, -2.9998], requires_grad=True), train_b: tensor([2.0000], requires_grad=True)\n",
      "Loss: 0.0002, train_W: tensor([ 2.0004, -2.9998], requires_grad=True), train_b: tensor([1.9999], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 2.0004, -2.9997], requires_grad=True), train_b: tensor([1.9999], requires_grad=True)\n",
      "Loss: 0.0002, train_W: tensor([ 2.0005, -2.9996], requires_grad=True), train_b: tensor([2.0002], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 2.0005, -2.9997], requires_grad=True), train_b: tensor([2.0002], requires_grad=True)\n",
      "Loss: 0.0006, train_W: tensor([ 2.0003, -2.9997], requires_grad=True), train_b: tensor([1.9999], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 2.0001, -2.9998], requires_grad=True), train_b: tensor([1.9995], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 2.0001, -2.9996], requires_grad=True), train_b: tensor([1.9997], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 2.0000, -2.9995], requires_grad=True), train_b: tensor([1.9998], requires_grad=True)\n",
      "Loss: 0.0008, train_W: tensor([ 2.0000, -2.9995], requires_grad=True), train_b: tensor([1.9996], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9995, -2.9997], requires_grad=True), train_b: tensor([1.9992], requires_grad=True)\n",
      "Loss: 0.0002, train_W: tensor([ 1.9998, -2.9995], requires_grad=True), train_b: tensor([1.9996], requires_grad=True)\n",
      "Loss: 0.0002, train_W: tensor([ 1.9997, -2.9995], requires_grad=True), train_b: tensor([1.9996], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9996, -2.9996], requires_grad=True), train_b: tensor([1.9992], requires_grad=True)\n",
      "Loss: 0.0006, train_W: tensor([ 1.9997, -2.9993], requires_grad=True), train_b: tensor([1.9996], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 2.0001, -2.9989], requires_grad=True), train_b: tensor([2.0001], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 2.0000, -2.9991], requires_grad=True), train_b: tensor([1.9999], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9999, -2.9992], requires_grad=True), train_b: tensor([1.9999], requires_grad=True)\n",
      "Loss: 0.0007, train_W: tensor([ 1.9996, -2.9992], requires_grad=True), train_b: tensor([1.9997], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9997, -2.9992], requires_grad=True), train_b: tensor([1.9997], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 1.9994, -2.9994], requires_grad=True), train_b: tensor([1.9991], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 1.9994, -2.9995], requires_grad=True), train_b: tensor([1.9991], requires_grad=True)\n",
      "Loss: 0.0006, train_W: tensor([ 1.9990, -2.9997], requires_grad=True), train_b: tensor([1.9985], requires_grad=True)\n",
      "Loss: 0.0008, train_W: tensor([ 1.9996, -2.9993], requires_grad=True), train_b: tensor([1.9992], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 1.9997, -2.9991], requires_grad=True), train_b: tensor([1.9994], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9995, -2.9992], requires_grad=True), train_b: tensor([1.9991], requires_grad=True)\n",
      "Loss: 0.0009, train_W: tensor([ 1.9996, -2.9991], requires_grad=True), train_b: tensor([1.9994], requires_grad=True)\n",
      "Loss: 0.0006, train_W: tensor([ 1.9994, -2.9996], requires_grad=True), train_b: tensor([1.9988], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 1.9997, -2.9995], requires_grad=True), train_b: tensor([1.9992], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9996, -2.9996], requires_grad=True), train_b: tensor([1.9990], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9996, -2.9998], requires_grad=True), train_b: tensor([1.9986], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 1.9999, -2.9996], requires_grad=True), train_b: tensor([1.9991], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 2.0000, -2.9994], requires_grad=True), train_b: tensor([1.9994], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 1.9998, -2.9997], requires_grad=True), train_b: tensor([1.9990], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 1.9997, -2.9996], requires_grad=True), train_b: tensor([1.9990], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 1.9995, -2.9997], requires_grad=True), train_b: tensor([1.9990], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9996, -2.9996], requires_grad=True), train_b: tensor([1.9992], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 1.9998, -2.9993], requires_grad=True), train_b: tensor([1.9997], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9998, -2.9994], requires_grad=True), train_b: tensor([1.9996], requires_grad=True)\n",
      "Loss: 0.0002, train_W: tensor([ 1.9999, -2.9993], requires_grad=True), train_b: tensor([1.9996], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9999, -2.9993], requires_grad=True), train_b: tensor([1.9995], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 1.9997, -2.9994], requires_grad=True), train_b: tensor([1.9993], requires_grad=True)\n",
      "Loss: 0.0012, train_W: tensor([ 1.9997, -2.9998], requires_grad=True), train_b: tensor([1.9987], requires_grad=True)\n",
      "Loss: 0.0002, train_W: tensor([ 1.9998, -2.9997], requires_grad=True), train_b: tensor([1.9988], requires_grad=True)\n",
      "Loss: 0.0011, train_W: tensor([ 2.0004, -2.9994], requires_grad=True), train_b: tensor([1.9995], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 2.0004, -2.9994], requires_grad=True), train_b: tensor([1.9996], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 2.0004, -2.9995], requires_grad=True), train_b: tensor([1.9996], requires_grad=True)\n",
      "Loss: 0.0008, train_W: tensor([ 2.0003, -2.9994], requires_grad=True), train_b: tensor([1.9998], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 2.0004, -2.9995], requires_grad=True), train_b: tensor([1.9999], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 2.0006, -2.9991], requires_grad=True), train_b: tensor([2.0004], requires_grad=True)\n",
      "Loss: 0.0002, train_W: tensor([ 2.0008, -2.9992], requires_grad=True), train_b: tensor([2.0006], requires_grad=True)\n",
      "Loss: 0.0007, train_W: tensor([ 2.0007, -2.9991], requires_grad=True), train_b: tensor([2.0007], requires_grad=True)\n",
      "Loss: 0.0007, train_W: tensor([ 2.0004, -2.9994], requires_grad=True), train_b: tensor([2.0003], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 2.0006, -2.9995], requires_grad=True), train_b: tensor([2.0002], requires_grad=True)\n",
      "Loss: 0.0008, train_W: tensor([ 2.0008, -2.9995], requires_grad=True), train_b: tensor([2.0005], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 2.0010, -2.9993], requires_grad=True), train_b: tensor([2.0007], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 2.0009, -2.9993], requires_grad=True), train_b: tensor([2.0006], requires_grad=True)\n",
      "Loss: 0.0008, train_W: tensor([ 2.0010, -2.9991], requires_grad=True), train_b: tensor([2.0008], requires_grad=True)\n",
      "Loss: 0.0007, train_W: tensor([ 2.0011, -2.9991], requires_grad=True), train_b: tensor([2.0009], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 2.0009, -2.9993], requires_grad=True), train_b: tensor([2.0007], requires_grad=True)\n",
      "Loss: 0.0002, train_W: tensor([ 2.0006, -2.9996], requires_grad=True), train_b: tensor([2.0001], requires_grad=True)\n",
      "Loss: 0.0006, train_W: tensor([ 2.0003, -2.9995], requires_grad=True), train_b: tensor([2.0002], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 2.0001, -2.9997], requires_grad=True), train_b: tensor([1.9999], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 2.0000, -2.9998], requires_grad=True), train_b: tensor([1.9996], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 1.9999, -2.9997], requires_grad=True), train_b: tensor([1.9996], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 1.9998, -2.9998], requires_grad=True), train_b: tensor([1.9996], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 1.9999, -2.9998], requires_grad=True), train_b: tensor([1.9996], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9999, -2.9998], requires_grad=True), train_b: tensor([1.9995], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9998, -2.9998], requires_grad=True), train_b: tensor([1.9995], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 1.9999, -2.9996], requires_grad=True), train_b: tensor([1.9996], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 2.0001, -2.9993], requires_grad=True), train_b: tensor([2.0001], requires_grad=True)\n",
      "Loss: 0.0007, train_W: tensor([ 2.0002, -2.9996], requires_grad=True), train_b: tensor([1.9999], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 2.0003, -2.9995], requires_grad=True), train_b: tensor([2.0002], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 2.0002, -2.9995], requires_grad=True), train_b: tensor([2.0001], requires_grad=True)\n",
      "Loss: 0.0006, train_W: tensor([ 2.0002, -2.9997], requires_grad=True), train_b: tensor([2.0002], requires_grad=True)\n",
      "Loss: 0.0006, train_W: tensor([ 2.0004, -2.9996], requires_grad=True), train_b: tensor([2.0002], requires_grad=True)\n",
      "Loss: 0.0001, train_W: tensor([ 2.0003, -2.9996], requires_grad=True), train_b: tensor([2.0001], requires_grad=True)\n",
      "Loss: 0.0006, train_W: tensor([ 2.0000, -2.9994], requires_grad=True), train_b: tensor([2.0001], requires_grad=True)\n",
      "Loss: 0.0006, train_W: tensor([ 2.0002, -2.9992], requires_grad=True), train_b: tensor([2.0007], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 2.0000, -2.9996], requires_grad=True), train_b: tensor([2.0003], requires_grad=True)\n",
      "Loss: 0.0006, train_W: tensor([ 1.9999, -2.9996], requires_grad=True), train_b: tensor([2.0001], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 1.9997, -2.9996], requires_grad=True), train_b: tensor([2.0000], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9999, -2.9996], requires_grad=True), train_b: tensor([2.0001], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 1.9999, -2.9996], requires_grad=True), train_b: tensor([2.0001], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9998, -2.9997], requires_grad=True), train_b: tensor([1.9998], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 1.9996, -2.9998], requires_grad=True), train_b: tensor([1.9997], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9998, -2.9998], requires_grad=True), train_b: tensor([2.0000], requires_grad=True)\n",
      "Loss: 0.0002, train_W: tensor([ 2.0000, -2.9998], requires_grad=True), train_b: tensor([2.0002], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 2.0000, -2.9997], requires_grad=True), train_b: tensor([2.0003], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 1.9998, -2.9999], requires_grad=True), train_b: tensor([2.0001], requires_grad=True)\n",
      "Loss: 0.0006, train_W: tensor([ 1.9997, -3.0001], requires_grad=True), train_b: tensor([1.9999], requires_grad=True)\n",
      "Loss: 0.0006, train_W: tensor([ 2.0001, -2.9997], requires_grad=True), train_b: tensor([2.0006], requires_grad=True)\n",
      "Loss: 0.0007, train_W: tensor([ 2.0001, -2.9998], requires_grad=True), train_b: tensor([2.0006], requires_grad=True)\n",
      "Loss: 0.0009, train_W: tensor([ 2.0000, -2.9997], requires_grad=True), train_b: tensor([2.0005], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 2.0006, -2.9991], requires_grad=True), train_b: tensor([2.0014], requires_grad=True)\n",
      "Loss: 0.0008, train_W: tensor([ 2.0004, -2.9993], requires_grad=True), train_b: tensor([2.0011], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 2.0003, -2.9997], requires_grad=True), train_b: tensor([2.0005], requires_grad=True)\n",
      "Loss: 0.0006, train_W: tensor([ 2.0001, -2.9999], requires_grad=True), train_b: tensor([2.0000], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 2.0002, -2.9999], requires_grad=True), train_b: tensor([2.0001], requires_grad=True)\n",
      "Loss: 0.0002, train_W: tensor([ 2.0004, -2.9999], requires_grad=True), train_b: tensor([2.0002], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 2.0003, -2.9999], requires_grad=True), train_b: tensor([2.0002], requires_grad=True)\n",
      "Loss: 0.0002, train_W: tensor([ 2.0002, -2.9999], requires_grad=True), train_b: tensor([2.0001], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 2.0003, -2.9998], requires_grad=True), train_b: tensor([2.0001], requires_grad=True)\n",
      "Loss: 0.0002, train_W: tensor([ 2.0003, -2.9997], requires_grad=True), train_b: tensor([2.0003], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 2.0004, -2.9998], requires_grad=True), train_b: tensor([2.0004], requires_grad=True)\n",
      "Loss: 0.0006, train_W: tensor([ 2.0001, -2.9998], requires_grad=True), train_b: tensor([2.0000], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9999, -2.9999], requires_grad=True), train_b: tensor([1.9997], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 2.0000, -2.9998], requires_grad=True), train_b: tensor([1.9999], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 1.9999, -2.9997], requires_grad=True), train_b: tensor([2.0000], requires_grad=True)\n",
      "Loss: 0.0008, train_W: tensor([ 1.9998, -2.9996], requires_grad=True), train_b: tensor([1.9997], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9994, -2.9998], requires_grad=True), train_b: tensor([1.9993], requires_grad=True)\n",
      "Loss: 0.0002, train_W: tensor([ 1.9996, -2.9996], requires_grad=True), train_b: tensor([1.9997], requires_grad=True)\n",
      "Loss: 0.0002, train_W: tensor([ 1.9995, -2.9996], requires_grad=True), train_b: tensor([1.9997], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9994, -2.9997], requires_grad=True), train_b: tensor([1.9994], requires_grad=True)\n",
      "Loss: 0.0006, train_W: tensor([ 1.9995, -2.9994], requires_grad=True), train_b: tensor([1.9998], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 2.0000, -2.9990], requires_grad=True), train_b: tensor([2.0003], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 1.9998, -2.9992], requires_grad=True), train_b: tensor([2.0001], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9998, -2.9993], requires_grad=True), train_b: tensor([2.0000], requires_grad=True)\n",
      "Loss: 0.0007, train_W: tensor([ 1.9995, -2.9994], requires_grad=True), train_b: tensor([1.9998], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9996, -2.9993], requires_grad=True), train_b: tensor([1.9998], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 1.9992, -2.9996], requires_grad=True), train_b: tensor([1.9992], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 1.9992, -2.9996], requires_grad=True), train_b: tensor([1.9992], requires_grad=True)\n",
      "Loss: 0.0006, train_W: tensor([ 1.9989, -2.9998], requires_grad=True), train_b: tensor([1.9986], requires_grad=True)\n",
      "Loss: 0.0008, train_W: tensor([ 1.9995, -2.9995], requires_grad=True), train_b: tensor([1.9994], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 1.9995, -2.9992], requires_grad=True), train_b: tensor([1.9995], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9993, -2.9993], requires_grad=True), train_b: tensor([1.9992], requires_grad=True)\n",
      "Loss: 0.0009, train_W: tensor([ 1.9995, -2.9992], requires_grad=True), train_b: tensor([1.9995], requires_grad=True)\n",
      "Loss: 0.0006, train_W: tensor([ 1.9993, -2.9997], requires_grad=True), train_b: tensor([1.9990], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 1.9996, -2.9996], requires_grad=True), train_b: tensor([1.9993], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9995, -2.9997], requires_grad=True), train_b: tensor([1.9992], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9994, -2.9999], requires_grad=True), train_b: tensor([1.9988], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 1.9998, -2.9997], requires_grad=True), train_b: tensor([1.9993], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9999, -2.9995], requires_grad=True), train_b: tensor([1.9996], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 1.9997, -2.9998], requires_grad=True), train_b: tensor([1.9991], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 1.9996, -2.9997], requires_grad=True), train_b: tensor([1.9991], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 1.9994, -2.9998], requires_grad=True), train_b: tensor([1.9991], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9995, -2.9997], requires_grad=True), train_b: tensor([1.9994], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 1.9997, -2.9994], requires_grad=True), train_b: tensor([1.9998], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9997, -2.9995], requires_grad=True), train_b: tensor([1.9997], requires_grad=True)\n",
      "Loss: 0.0002, train_W: tensor([ 1.9997, -2.9994], requires_grad=True), train_b: tensor([1.9998], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9997, -2.9994], requires_grad=True), train_b: tensor([1.9997], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 1.9996, -2.9995], requires_grad=True), train_b: tensor([1.9995], requires_grad=True)\n",
      "Loss: 0.0012, train_W: tensor([ 1.9996, -2.9999], requires_grad=True), train_b: tensor([1.9988], requires_grad=True)\n",
      "Loss: 0.0002, train_W: tensor([ 1.9997, -2.9998], requires_grad=True), train_b: tensor([1.9989], requires_grad=True)\n",
      "Loss: 0.0011, train_W: tensor([ 2.0003, -2.9996], requires_grad=True), train_b: tensor([1.9996], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 2.0003, -2.9995], requires_grad=True), train_b: tensor([1.9997], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 2.0003, -2.9996], requires_grad=True), train_b: tensor([1.9997], requires_grad=True)\n",
      "Loss: 0.0008, train_W: tensor([ 2.0002, -2.9995], requires_grad=True), train_b: tensor([1.9999], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 2.0003, -2.9996], requires_grad=True), train_b: tensor([2.0000], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 2.0005, -2.9993], requires_grad=True), train_b: tensor([2.0005], requires_grad=True)\n",
      "Loss: 0.0002, train_W: tensor([ 2.0006, -2.9993], requires_grad=True), train_b: tensor([2.0007], requires_grad=True)\n",
      "Loss: 0.0007, train_W: tensor([ 2.0005, -2.9992], requires_grad=True), train_b: tensor([2.0008], requires_grad=True)\n",
      "Loss: 0.0007, train_W: tensor([ 2.0003, -2.9996], requires_grad=True), train_b: tensor([2.0004], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 2.0004, -2.9996], requires_grad=True), train_b: tensor([2.0003], requires_grad=True)\n",
      "Loss: 0.0007, train_W: tensor([ 2.0007, -2.9996], requires_grad=True), train_b: tensor([2.0006], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 2.0009, -2.9994], requires_grad=True), train_b: tensor([2.0009], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 2.0008, -2.9995], requires_grad=True), train_b: tensor([2.0008], requires_grad=True)\n",
      "Loss: 0.0008, train_W: tensor([ 2.0009, -2.9992], requires_grad=True), train_b: tensor([2.0009], requires_grad=True)\n",
      "Loss: 0.0007, train_W: tensor([ 2.0010, -2.9992], requires_grad=True), train_b: tensor([2.0010], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 2.0008, -2.9994], requires_grad=True), train_b: tensor([2.0008], requires_grad=True)\n",
      "Loss: 0.0002, train_W: tensor([ 2.0004, -2.9997], requires_grad=True), train_b: tensor([2.0003], requires_grad=True)\n",
      "Loss: 0.0006, train_W: tensor([ 2.0002, -2.9996], requires_grad=True), train_b: tensor([2.0003], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 2.0000, -2.9998], requires_grad=True), train_b: tensor([2.0000], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9999, -2.9999], requires_grad=True), train_b: tensor([1.9997], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 1.9998, -2.9998], requires_grad=True), train_b: tensor([1.9997], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 1.9997, -2.9999], requires_grad=True), train_b: tensor([1.9997], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 1.9998, -2.9999], requires_grad=True), train_b: tensor([1.9997], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9998, -2.9999], requires_grad=True), train_b: tensor([1.9997], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9997, -2.9998], requires_grad=True), train_b: tensor([1.9996], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 1.9998, -2.9997], requires_grad=True), train_b: tensor([1.9997], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 2.0000, -2.9994], requires_grad=True), train_b: tensor([2.0002], requires_grad=True)\n",
      "Loss: 0.0007, train_W: tensor([ 2.0001, -2.9997], requires_grad=True), train_b: tensor([2.0000], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 2.0002, -2.9996], requires_grad=True), train_b: tensor([2.0003], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 2.0001, -2.9996], requires_grad=True), train_b: tensor([2.0002], requires_grad=True)\n",
      "Loss: 0.0006, train_W: tensor([ 2.0001, -2.9998], requires_grad=True), train_b: tensor([2.0003], requires_grad=True)\n",
      "Loss: 0.0006, train_W: tensor([ 2.0003, -2.9997], requires_grad=True), train_b: tensor([2.0003], requires_grad=True)\n",
      "Loss: 0.0001, train_W: tensor([ 2.0002, -2.9997], requires_grad=True), train_b: tensor([2.0002], requires_grad=True)\n",
      "Loss: 0.0006, train_W: tensor([ 1.9999, -2.9995], requires_grad=True), train_b: tensor([2.0003], requires_grad=True)\n",
      "Loss: 0.0006, train_W: tensor([ 2.0001, -2.9993], requires_grad=True), train_b: tensor([2.0008], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 1.9999, -2.9997], requires_grad=True), train_b: tensor([2.0004], requires_grad=True)\n",
      "Loss: 0.0006, train_W: tensor([ 1.9998, -2.9996], requires_grad=True), train_b: tensor([2.0002], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 1.9996, -2.9997], requires_grad=True), train_b: tensor([2.0001], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9998, -2.9997], requires_grad=True), train_b: tensor([2.0002], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 1.9998, -2.9997], requires_grad=True), train_b: tensor([2.0002], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9997, -2.9998], requires_grad=True), train_b: tensor([1.9999], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 1.9995, -2.9999], requires_grad=True), train_b: tensor([1.9998], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9997, -2.9999], requires_grad=True), train_b: tensor([2.0001], requires_grad=True)\n",
      "Loss: 0.0002, train_W: tensor([ 1.9999, -2.9999], requires_grad=True), train_b: tensor([2.0003], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 1.9999, -2.9998], requires_grad=True), train_b: tensor([2.0004], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 1.9997, -3.0000], requires_grad=True), train_b: tensor([2.0001], requires_grad=True)\n",
      "Loss: 0.0006, train_W: tensor([ 1.9996, -3.0001], requires_grad=True), train_b: tensor([2.0000], requires_grad=True)\n",
      "Loss: 0.0006, train_W: tensor([ 2.0000, -2.9998], requires_grad=True), train_b: tensor([2.0007], requires_grad=True)\n",
      "Loss: 0.0007, train_W: tensor([ 2.0000, -2.9999], requires_grad=True), train_b: tensor([2.0007], requires_grad=True)\n",
      "Loss: 0.0009, train_W: tensor([ 1.9999, -2.9998], requires_grad=True), train_b: tensor([2.0006], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 2.0005, -2.9992], requires_grad=True), train_b: tensor([2.0015], requires_grad=True)\n",
      "Loss: 0.0008, train_W: tensor([ 2.0003, -2.9994], requires_grad=True), train_b: tensor([2.0012], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 2.0002, -2.9998], requires_grad=True), train_b: tensor([2.0006], requires_grad=True)\n",
      "Loss: 0.0006, train_W: tensor([ 2.0000, -3.0000], requires_grad=True), train_b: tensor([2.0001], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 2.0001, -3.0000], requires_grad=True), train_b: tensor([2.0002], requires_grad=True)\n",
      "Loss: 0.0002, train_W: tensor([ 2.0003, -3.0000], requires_grad=True), train_b: tensor([2.0003], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 2.0002, -3.0000], requires_grad=True), train_b: tensor([2.0003], requires_grad=True)\n",
      "Loss: 0.0002, train_W: tensor([ 2.0001, -3.0000], requires_grad=True), train_b: tensor([2.0002], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 2.0002, -2.9999], requires_grad=True), train_b: tensor([2.0002], requires_grad=True)\n",
      "Loss: 0.0002, train_W: tensor([ 2.0003, -2.9998], requires_grad=True), train_b: tensor([2.0004], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 2.0003, -2.9999], requires_grad=True), train_b: tensor([2.0004], requires_grad=True)\n",
      "Loss: 0.0006, train_W: tensor([ 2.0000, -2.9999], requires_grad=True), train_b: tensor([2.0001], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9999, -3.0000], requires_grad=True), train_b: tensor([1.9998], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9999, -2.9998], requires_grad=True), train_b: tensor([2.0000], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 1.9998, -2.9998], requires_grad=True), train_b: tensor([2.0000], requires_grad=True)\n",
      "Loss: 0.0008, train_W: tensor([ 1.9997, -2.9997], requires_grad=True), train_b: tensor([1.9998], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9993, -2.9999], requires_grad=True), train_b: tensor([1.9994], requires_grad=True)\n",
      "Loss: 0.0002, train_W: tensor([ 1.9995, -2.9997], requires_grad=True), train_b: tensor([1.9998], requires_grad=True)\n",
      "Loss: 0.0002, train_W: tensor([ 1.9994, -2.9997], requires_grad=True), train_b: tensor([1.9998], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9994, -2.9998], requires_grad=True), train_b: tensor([1.9994], requires_grad=True)\n",
      "Loss: 0.0006, train_W: tensor([ 1.9994, -2.9995], requires_grad=True), train_b: tensor([1.9998], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 1.9999, -2.9991], requires_grad=True), train_b: tensor([2.0004], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 1.9997, -2.9993], requires_grad=True), train_b: tensor([2.0002], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9997, -2.9994], requires_grad=True), train_b: tensor([2.0001], requires_grad=True)\n",
      "Loss: 0.0007, train_W: tensor([ 1.9994, -2.9994], requires_grad=True), train_b: tensor([1.9999], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9995, -2.9994], requires_grad=True), train_b: tensor([1.9999], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 1.9992, -2.9996], requires_grad=True), train_b: tensor([1.9993], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 1.9991, -2.9997], requires_grad=True), train_b: tensor([1.9993], requires_grad=True)\n",
      "Loss: 0.0006, train_W: tensor([ 1.9988, -2.9999], requires_grad=True), train_b: tensor([1.9987], requires_grad=True)\n",
      "Loss: 0.0008, train_W: tensor([ 1.9994, -2.9995], requires_grad=True), train_b: tensor([1.9995], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 1.9995, -2.9993], requires_grad=True), train_b: tensor([1.9996], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9993, -2.9994], requires_grad=True), train_b: tensor([1.9993], requires_grad=True)\n",
      "Loss: 0.0009, train_W: tensor([ 1.9994, -2.9993], requires_grad=True), train_b: tensor([1.9996], requires_grad=True)\n",
      "Loss: 0.0006, train_W: tensor([ 1.9992, -2.9998], requires_grad=True), train_b: tensor([1.9990], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 1.9995, -2.9997], requires_grad=True), train_b: tensor([1.9994], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9994, -2.9998], requires_grad=True), train_b: tensor([1.9993], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9993, -3.0000], requires_grad=True), train_b: tensor([1.9988], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 1.9997, -2.9998], requires_grad=True), train_b: tensor([1.9993], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9998, -2.9996], requires_grad=True), train_b: tensor([1.9997], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 1.9996, -2.9998], requires_grad=True), train_b: tensor([1.9992], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 1.9995, -2.9998], requires_grad=True), train_b: tensor([1.9992], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 1.9993, -2.9999], requires_grad=True), train_b: tensor([1.9992], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9994, -2.9998], requires_grad=True), train_b: tensor([1.9994], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 1.9996, -2.9995], requires_grad=True), train_b: tensor([1.9999], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9996, -2.9995], requires_grad=True), train_b: tensor([1.9998], requires_grad=True)\n",
      "Loss: 0.0002, train_W: tensor([ 1.9997, -2.9994], requires_grad=True), train_b: tensor([1.9998], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9997, -2.9995], requires_grad=True), train_b: tensor([1.9997], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 1.9995, -2.9995], requires_grad=True), train_b: tensor([1.9995], requires_grad=True)\n",
      "Loss: 0.0012, train_W: tensor([ 1.9995, -3.0000], requires_grad=True), train_b: tensor([1.9989], requires_grad=True)\n",
      "Loss: 0.0002, train_W: tensor([ 1.9996, -2.9999], requires_grad=True), train_b: tensor([1.9990], requires_grad=True)\n",
      "Loss: 0.0011, train_W: tensor([ 2.0002, -2.9996], requires_grad=True), train_b: tensor([1.9997], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 2.0002, -2.9995], requires_grad=True), train_b: tensor([1.9998], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 2.0002, -2.9996], requires_grad=True), train_b: tensor([1.9998], requires_grad=True)\n",
      "Loss: 0.0008, train_W: tensor([ 2.0001, -2.9995], requires_grad=True), train_b: tensor([2.0000], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 2.0002, -2.9996], requires_grad=True), train_b: tensor([2.0001], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 2.0005, -2.9993], requires_grad=True), train_b: tensor([2.0006], requires_grad=True)\n",
      "Loss: 0.0002, train_W: tensor([ 2.0006, -2.9994], requires_grad=True), train_b: tensor([2.0007], requires_grad=True)\n",
      "Loss: 0.0007, train_W: tensor([ 2.0005, -2.9993], requires_grad=True), train_b: tensor([2.0009], requires_grad=True)\n",
      "Loss: 0.0007, train_W: tensor([ 2.0002, -2.9996], requires_grad=True), train_b: tensor([2.0004], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 2.0004, -2.9997], requires_grad=True), train_b: tensor([2.0004], requires_grad=True)\n",
      "Loss: 0.0007, train_W: tensor([ 2.0006, -2.9997], requires_grad=True), train_b: tensor([2.0007], requires_grad=True)\n",
      "Loss: 0.0006, train_W: tensor([ 2.0008, -2.9994], requires_grad=True), train_b: tensor([2.0009], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 2.0007, -2.9995], requires_grad=True), train_b: tensor([2.0008], requires_grad=True)\n",
      "Loss: 0.0008, train_W: tensor([ 2.0008, -2.9993], requires_grad=True), train_b: tensor([2.0010], requires_grad=True)\n",
      "Loss: 0.0007, train_W: tensor([ 2.0009, -2.9993], requires_grad=True), train_b: tensor([2.0011], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 2.0007, -2.9995], requires_grad=True), train_b: tensor([2.0009], requires_grad=True)\n",
      "Loss: 0.0002, train_W: tensor([ 2.0004, -2.9997], requires_grad=True), train_b: tensor([2.0003], requires_grad=True)\n",
      "Loss: 0.0006, train_W: tensor([ 2.0001, -2.9996], requires_grad=True), train_b: tensor([2.0003], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 2.0000, -2.9998], requires_grad=True), train_b: tensor([2.0000], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9998, -3.0000], requires_grad=True), train_b: tensor([1.9998], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 1.9997, -2.9999], requires_grad=True), train_b: tensor([1.9997], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 1.9996, -2.9999], requires_grad=True), train_b: tensor([1.9997], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 1.9997, -2.9999], requires_grad=True), train_b: tensor([1.9998], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9997, -2.9999], requires_grad=True), train_b: tensor([1.9997], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9997, -2.9999], requires_grad=True), train_b: tensor([1.9997], requires_grad=True)\n",
      "Loss: 0.0005, train_W: tensor([ 1.9998, -2.9997], requires_grad=True), train_b: tensor([1.9998], requires_grad=True)\n",
      "Loss: 0.0004, train_W: tensor([ 1.9999, -2.9995], requires_grad=True), train_b: tensor([2.0003], requires_grad=True)\n",
      "Loss: 0.0007, train_W: tensor([ 2.0000, -2.9998], requires_grad=True), train_b: tensor([2.0001], requires_grad=True)\n",
      "Loss: 0.0003, train_W: tensor([ 2.0001, -2.9996], requires_grad=True), train_b: tensor([2.0003], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for train_X, train_y in data_iter(batch_size, X, y):\n",
    "        y_pred = linrg(train_X)\n",
    "        l = loss(train_y, y_pred)\n",
    "        l.sum().backward()\n",
    "        sgd((train_W, train_b), lr, batch_size)\n",
    "        print(f'Loss: {l.sum():.4f}, train_W: {train_W}, train_b: {train_b}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
