{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "patient-comfort",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "from d2l import torch as d2l\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "excited-reputation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "under-offering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# sentences: 42069'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@save\n",
    "d2l.DATA_HUB['ptb'] = (d2l.DATA_URL + 'ptb.zip',\n",
    "                       '319d85e578af0cdc590547f26231e4e31cdf1e42')\n",
    "\n",
    "#@save\n",
    "def read_ptb():\n",
    "    \"\"\"Load the PTB dataset into a list of text lines.\"\"\"\n",
    "    data_dir = d2l.download_extract('ptb')\n",
    "    # Read the training set.\n",
    "    with open(os.path.join(data_dir, 'ptb.train.txt')) as f:\n",
    "        raw_text = f.read()\n",
    "    return [line.split() for line in raw_text.split('\\n')]\n",
    "\n",
    "sentences = read_ptb()\n",
    "f'# sentences: {len(sentences)}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "preliminary-trigger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vocab size: 6719'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = d2l.Vocab(sentences, min_freq=10)\n",
    "f'vocab size: {len(vocab)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "handed-formula",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.unk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "adequate-techno",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsample(sentences, vocab):\n",
    "    \n",
    "    list_sentences = []\n",
    "    for line in sentences:\n",
    "        for token in line:\n",
    "            if (vocab[token] != vocab.unk):\n",
    "                list_sentences.append(token)\n",
    "    counter = Counter(list_sentences)\n",
    "    \n",
    "    num_tokens = sum(counter.values())\n",
    "    def keep(token):\n",
    "        return (random.uniform(0, 1) < math.sqrt((1e-4)/counter[token]*num_tokens))\n",
    "    return [[token for token in line if vocab[token] != vocab.unk and keep(token)] for line in sentences], counter\n",
    "\n",
    "sub, counter = subsample(sentences, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "future-fitting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.200e+02, 1.247e+03, 2.298e+03, 2.093e+03, 4.191e+03, 4.709e+03,\n",
       "        4.910e+03, 3.265e+03, 4.525e+03, 4.062e+03, 3.279e+03, 1.649e+03,\n",
       "        1.825e+03, 1.308e+03, 6.150e+02, 6.730e+02, 3.790e+02, 2.210e+02,\n",
       "        1.180e+02, 9.600e+01, 7.400e+01, 4.000e+01, 2.200e+01, 1.100e+01,\n",
       "        9.000e+00, 9.000e+00, 7.000e+00, 5.000e+00, 5.000e+00, 4.000e+00]),\n",
       " array([ 0.        ,  2.73333333,  5.46666667,  8.2       , 10.93333333,\n",
       "        13.66666667, 16.4       , 19.13333333, 21.86666667, 24.6       ,\n",
       "        27.33333333, 30.06666667, 32.8       , 35.53333333, 38.26666667,\n",
       "        41.        , 43.73333333, 46.46666667, 49.2       , 51.93333333,\n",
       "        54.66666667, 57.4       , 60.13333333, 62.86666667, 65.6       ,\n",
       "        68.33333333, 71.06666667, 73.8       , 76.53333333, 79.26666667,\n",
       "        82.        ]),\n",
       " <BarContainer object of 30 artists>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(x) for x in sub], bins=30)\n",
    "plt.hist([len(x) for x in sentences], bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "instructional-thirty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2053, 50770)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_count(token):\n",
    "    return (sum(l.count(token) for l in sub), sum(l.count(token) for l in sentences))\n",
    "compare_count('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "mighty-princess",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [vocab[line] for line in sub]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "perceived-northern",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [392, 2115], [140, 5277, 3054, 1580]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "martial-windsor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centers_and_contexts(corpus, max_window_size):\n",
    "    centers, contexts = [], []\n",
    "    \n",
    "    for line in corpus:\n",
    "        if (len(line) < 2):\n",
    "            continue\n",
    "        centers += line\n",
    "        for i in range(len(line)):\n",
    "            window_size = random.randint(1, max_window_size)\n",
    "            indicies = list(range(\n",
    "                max(0, i - window_size),\n",
    "                min(len(line), i + window_size + 1)\n",
    "            ))\n",
    "            indicies.remove(i)\n",
    "            contexts.append([line[idx] for idx in indicies])\n",
    "    return centers, contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "wired-jacob",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "center 0 has context [1, 2]\n",
      "center 1 has context [0, 2, 3]\n",
      "center 2 has context [1, 3]\n",
      "center 3 has context [1, 2, 4, 5]\n",
      "center 4 has context [2, 3, 5, 6]\n",
      "center 5 has context [3, 4, 6]\n",
      "center 6 has context [5]\n",
      "center 7 has context [8]\n",
      "center 8 has context [7, 9]\n",
      "center 9 has context [8]\n"
     ]
    }
   ],
   "source": [
    "# corpus = [list(range(7)), list(range(7, 10))]\n",
    "# centers, contexts = get_centers_and_contexts(corpus, 2)\n",
    "# for c, ct in zip(centers, contexts):\n",
    "#     print(f'center {c} has context {ct}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "reverse-implement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# center-context pairs: 1500164'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_centers, all_contexts = get_centers_and_contexts(corpus, 5)\n",
    "f'# center-context pairs: {sum([len(contexts) for contexts in all_contexts])}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "apart-invention",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomGenerator:\n",
    "    def __init__(self, sampling_weights):\n",
    "#         sampling_weights can be unnormalized distribution\n",
    "        self.population = list(range(1, len(sampling_weights) + 1)) # ignore unk token\n",
    "        self.sampling_weights = sampling_weights \n",
    "        # for cache\n",
    "        self.candidates = []\n",
    "        self.i = 0\n",
    "    def draw(self):\n",
    "        if self.i == len(self.candidates):\n",
    "            # redraw after use all of candidates\n",
    "            self.candidates = random.choices(self.population, self.sampling_weights, k=10000)\n",
    "            self.i = 0\n",
    "        self.i += 1\n",
    "        return self.candidates[self.i - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "literary-reservation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 3, 3, 3, 2, 1, 2, 3, 1, 3]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = RandomGenerator([1, 2, 3])\n",
    "[gen.draw() for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "phantom-sharing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_negatives(all_contexts, vocab, counter, K):\n",
    "    sampling_weights = [counter[vocab.to_tokens(i)] for i in range(1, len(vocab))]\n",
    "    gen = RandomGenerator(sampling_weights)\n",
    "    all_negatives = []\n",
    "    \n",
    "    for context in all_contexts:\n",
    "        negatives = []\n",
    "        while len(negatives) < len(context) * K:\n",
    "            neg_idx = gen.draw()\n",
    "            if (neg_idx not in context):\n",
    "                negatives.append(neg_idx)\n",
    "        all_negatives.append(negatives)\n",
    "    return all_negatives\n",
    "\n",
    "all_negatives = get_negatives(all_contexts, vocab, counter, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "generic-yukon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([179, 2136, 2, 18, 178], [2115])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_negatives[0], all_contexts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "vocational-young",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(data):\n",
    "    max_len = max(len(c) + len(n) for _, c, n in data)\n",
    "    centers, context_negatives, masks, labels = [], [], [], []\n",
    "    \n",
    "    for center, context, negative in data:\n",
    "        cur_len = len(context) + len(negative)\n",
    "        centers += [center]\n",
    "        context_negatives += [context + negative + [0]*(max_len - cur_len)]\n",
    "        masks += [[1] * cur_len + [0] * (max_len - cur_len)]\n",
    "        labels += [[1] * len(context) + [0] * (max_len - len(context))]\n",
    "    return np.array(centers).reshape((-1, 1)), np.array(context_negatives), np.array(masks), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "prostate-somewhere",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centers = [[1]\n",
      " [1]]\n",
      "contexts_negatives = [[2 2 3 3 3 3]\n",
      " [2 2 2 3 3 0]]\n",
      "masks = [[1 1 1 1 1 1]\n",
      " [1 1 1 1 1 0]]\n",
      "labels = [[1 1 0 0 0 0]\n",
      " [1 1 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "x_1 = (1, [2, 2], [3, 3, 3, 3])\n",
    "x_2 = (1, [2, 2, 2], [3, 3])\n",
    "batch = batchify((x_1, x_2))\n",
    "\n",
    "names = ['centers', 'contexts_negatives', 'masks', 'labels']\n",
    "for name, data in zip(names, batch):\n",
    "    print(name, '=', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "clean-advertising",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def load_data_ptb(batch_size, max_window_size, num_noise_words):\n",
    "    \"\"\"Download the PTB dataset and then load it into memory.\"\"\"\n",
    "    num_workers = d2l.get_dataloader_workers()\n",
    "    sentences = read_ptb()\n",
    "    vocab = d2l.Vocab(sentences, min_freq=10)\n",
    "    subsampled, counter = subsample(sentences, vocab)\n",
    "    corpus = [vocab[line] for line in subsampled]\n",
    "    all_centers, all_contexts = get_centers_and_contexts(\n",
    "        corpus, max_window_size)\n",
    "    all_negatives = get_negatives(all_contexts, vocab, counter,\n",
    "                                  num_noise_words)\n",
    "\n",
    "    class PTBDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, centers, contexts, negatives):\n",
    "            assert len(centers) == len(contexts) == len(negatives)\n",
    "            self.centers = centers\n",
    "            self.contexts = contexts\n",
    "            self.negatives = negatives\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            return (self.centers[index], self.contexts[index],\n",
    "                    self.negatives[index])\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.centers)\n",
    "\n",
    "    dataset = PTBDataset(all_centers, all_contexts, all_negatives)\n",
    "\n",
    "    data_iter = torch.utils.data.DataLoader(dataset, batch_size, shuffle=True,\n",
    "                                            collate_fn=batchify,\n",
    "                                            num_workers=num_workers)\n",
    "    return data_iter, vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "unauthorized-newfoundland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centers shape: (512, 1)\n",
      "contexts_negatives shape: (512, 60)\n",
      "masks shape: (512, 60)\n",
      "labels shape: (512, 60)\n"
     ]
    }
   ],
   "source": [
    "data_iter, vocab = load_data_ptb(512, 5, 5)\n",
    "for batch in data_iter:\n",
    "    for name, data in zip(names, batch):\n",
    "        print(name, 'shape:', data.shape)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
