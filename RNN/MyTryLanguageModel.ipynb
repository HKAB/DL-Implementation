{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detailed-fellowship",
   "metadata": {},
   "outputs": [],
   "source": [
    "from d2l import torch as d2l\n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "charitable-reggae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 2261),\n",
       " ('i', 1267),\n",
       " ('and', 1245),\n",
       " ('of', 1155),\n",
       " ('a', 816),\n",
       " ('to', 695),\n",
       " ('was', 552),\n",
       " ('in', 541),\n",
       " ('that', 443),\n",
       " ('my', 440)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "from d2l import torch as d2l\n",
    "\n",
    "tokens = d2l.tokenize(d2l.read_time_machine())\n",
    "# Since each text line is not necessarily a sentence or a paragraph, we\n",
    "# concatenate all text lines\n",
    "corpus = [token for line in tokens for token in line]\n",
    "vocab = d2l.Vocab(corpus)\n",
    "vocab.token_freqs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "organized-tablet",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = [pair for pair in zip(corpus[:-1], corpus[1:])]\n",
    "bigram_vocab = d2l.Vocab(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "empty-stranger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('the', 'time', 'traveller'), 59),\n",
       " (('the', 'time', 'machine'), 30),\n",
       " (('the', 'medical', 'man'), 24),\n",
       " (('it', 'seemed', 'to'), 16),\n",
       " (('it', 'was', 'a'), 15),\n",
       " (('here', 'and', 'there'), 15),\n",
       " (('seemed', 'to', 'me'), 14),\n",
       " (('i', 'did', 'not'), 14),\n",
       " (('i', 'saw', 'the'), 13),\n",
       " (('i', 'began', 'to'), 13)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram = [trip for trip in zip(corpus[:-2], corpus[1:-1], corpus[2:])]\n",
    "trigram_vocab = d2l.Vocab(trigram)\n",
    "trigram_vocab.token_freqs[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-custom",
   "metadata": {},
   "source": [
    "## Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "latter-oklahoma",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_data_iter_random(corpus, batch_size, num_steps):\n",
    "#     print(int((len(corpus) - 1)/num_steps))\n",
    "    initial_indices = list(range((len(corpus) - 1)//num_steps*num_steps))\n",
    "    random.shuffle(initial_indices)\n",
    "    \n",
    "    for i in range(0, int((len(corpus) - 1)/num_steps), batch_size):\n",
    "        X = []\n",
    "        y = []\n",
    "        for j in range(batch_size):\n",
    "#             rand_idx = random.randint(0, len(corpus) - num_steps - 1)\n",
    "            X.append(torch.tensor(corpus[initial_indices[i + j]: initial_indices[i + j] + num_steps]))\n",
    "            y.append(torch.tensor(corpus[initial_indices[i + j] + 1: initial_indices[i + j] + num_steps + 1]))\n",
    "        yield X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "turned-logging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  [tensor([ 9, 10, 11, 12, 13]), tensor([25, 26, 27, 28, 29]), tensor([12, 13, 14, 15, 16])] \n",
      "Y: [tensor([10, 11, 12, 13, 14]), tensor([26, 27, 28, 29, 30]), tensor([13, 14, 15, 16, 17])]\n",
      "X:  [tensor([26, 27, 28, 29, 30]), tensor([22, 23, 24, 25, 26]), tensor([24, 25, 26, 27, 28])] \n",
      "Y: [tensor([27, 28, 29, 30, 31]), tensor([23, 24, 25, 26, 27]), tensor([25, 26, 27, 28, 29])]\n"
     ]
    }
   ],
   "source": [
    "my_seq = list(range(35))\n",
    "for X, Y in seq_data_iter_random(my_seq, batch_size=3, num_steps=5):\n",
    "    print('X: ', X, '\\nY:', Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-rabbit",
   "metadata": {},
   "source": [
    "## Sequential Partioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "unable-karen",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_data_iter_sequential(corpus, batch_size, num_steps):\n",
    "    initial_indices = list(range((len(corpus) - 1)//num_steps*num_steps))\n",
    "    \n",
    "    batch_start_index = []\n",
    "    for i in range(0, batch_size):\n",
    "        batch_start_index.append(i*int((len(corpus) - 1)//num_steps)//batch_size*num_steps)\n",
    "        \n",
    "    for i in range(0, int((len(corpus) - 1)/num_steps)//batch_size):\n",
    "        X = []\n",
    "        y = []\n",
    "        for j in range(batch_size):\n",
    "#             rand_idx = random.randint(0, len(corpus) - num_steps - 1)\n",
    "#             t = int((len(corpus) - 1)//num_steps)//batch_size*num_steps\n",
    "            X.append(torch.tensor(corpus[batch_start_index[j] + i*num_steps: batch_start_index[j] + i*num_steps + num_steps]))\n",
    "            y.append(torch.tensor(corpus[batch_start_index[j] + i*num_steps + 1: batch_start_index[j] + i*num_steps + num_steps + 1]))\n",
    "        yield torch.stack(X), torch.stack(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "adaptive-dragon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  tensor([[ 0,  1,  2,  3,  4],\n",
      "        [15, 16, 17, 18, 19]]) \n",
      "Y: tensor([[ 1,  2,  3,  4,  5],\n",
      "        [16, 17, 18, 19, 20]])\n",
      "X:  tensor([[ 5,  6,  7,  8,  9],\n",
      "        [20, 21, 22, 23, 24]]) \n",
      "Y: tensor([[ 6,  7,  8,  9, 10],\n",
      "        [21, 22, 23, 24, 25]])\n",
      "X:  tensor([[10, 11, 12, 13, 14],\n",
      "        [25, 26, 27, 28, 29]]) \n",
      "Y: tensor([[11, 12, 13, 14, 15],\n",
      "        [26, 27, 28, 29, 30]])\n"
     ]
    }
   ],
   "source": [
    "my_seq = list(range(35))\n",
    "for X, Y in seq_data_iter_sequential(my_seq, batch_size=2, num_steps=5):\n",
    "    print('X: ', X, '\\nY:', Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
